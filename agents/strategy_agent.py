"""
PropelAI Strategy Agent - "The Capture Manager"
Play 2: The Strategy Engine (Win Themes)

v4.0: Enhanced with real LLM integration for strategic analysis

Goal: Define *why* we win before writing a single word

This agent:
1. Analyzes Section M (Evaluation Factors) using LLM reasoning
2. Queries past bid strategies from the Agent-Trace database
3. Performs competitor ghosting analysis
4. Generates win themes and discriminators via LLM
5. Creates annotated outline with page allocations

Uses high-reasoning model (Gemini 1.5 Pro or Claude) for strategic synthesis
"""

import json
import re
import os
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum

try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False

from core.state import ProposalState, ProposalPhase


# LLM Provider configuration
LLM_PROVIDERS = {
    "gemini": {
        "base_url": "https://generativelanguage.googleapis.com/v1beta",
        "model": "gemini-1.5-pro",
        "env_key": "GOOGLE_API_KEY",
    },
    "anthropic": {
        "base_url": "https://api.anthropic.com/v1",
        "model": "claude-3-5-sonnet-20241022",
        "env_key": "ANTHROPIC_API_KEY",
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "model": "gpt-4-turbo-preview",
        "env_key": "OPENAI_API_KEY",
    },
}


class StrategyFramework(str, Enum):
    """Common proposal strategy frameworks"""
    PRICE_TO_WIN = "price_to_win"
    TECHNICAL_EXCELLENCE = "technical_excellence"
    PAST_PERFORMANCE = "past_performance"
    INNOVATION = "innovation"
    RISK_MITIGATION = "risk_mitigation"
    PARTNERSHIP = "partnership"
    TRANSITION = "transition"


class DiscriminatorType(str, Enum):
    """Categories of discriminators"""
    TECHNICAL = "technical"
    MANAGEMENT = "management"
    PAST_PERFORMANCE = "past_performance"
    PRICE = "price"
    INNOVATION = "innovation"
    RISK = "risk"
    PERSONNEL = "personnel"


@dataclass
class Discriminator:
    """
    v4.0 Iron Triangle: A unique differentiator that sets us apart.

    Each discriminator should be:
    - Provable with evidence
    - Relevant to evaluation criteria
    - Difficult for competitors to match
    """
    id: str
    category: DiscriminatorType
    claim: str                         # "Our patented AI reduces review time by 40%"
    evidence_type: str                 # "case_study" | "metric" | "testimonial" | "certification"
    evidence_source: Optional[str]     # Document reference
    quantified_impact: Optional[str]   # "40% faster" | "$2M saved"
    ghosting_angle: Optional[str]      # How this positions against competitors


@dataclass
class WinTheme:
    """
    v4.0 Iron Triangle: A strategic win theme with full evidence chain.

    Each theme addresses a primary evaluation factor with:
    - Clear headline message
    - Multiple discriminators
    - Provable evidence points
    - Competitive positioning
    """
    id: str
    theme_headline: str                # The headline message (1 sentence)
    theme_narrative: str               # 2-3 sentence expansion
    discriminators: List[Discriminator] = field(default_factory=list)
    proof_points: List[str] = field(default_factory=list)
    linked_eval_criteria: List[str] = field(default_factory=list)
    ghosting_language: Optional[str] = None
    page_allocation_percent: float = 0.0  # Suggested % of volume
    priority: int = 1                  # 1-5 ranking (1 = highest)
    confidence: float = 0.5
    llm_generated: bool = False        # True if generated by LLM vs template

    # Legacy compatibility
    @property
    def theme_text(self) -> str:
        return self.theme_headline

    @property
    def discriminator(self) -> str:
        if self.discriminators:
            return self.discriminators[0].claim
        return ""

    @property
    def linked_criteria(self) -> List[str]:
        return self.linked_eval_criteria


@dataclass
class CompetitorProfile:
    """Intelligence on a competitor"""
    name: str
    strengths: List[str] = field(default_factory=list)
    weaknesses: List[str] = field(default_factory=list)
    likely_themes: List[str] = field(default_factory=list)
    ghosting_opportunities: List[str] = field(default_factory=list)


@dataclass
class GhostingStrategy:
    """
    v4.0: Subtle competitive positioning language.

    Ghosting is about positioning ourselves favorably without
    directly naming competitors.
    """
    competitor_weakness: str           # What competitor lacks
    our_strength: str                  # Our counter-positioning
    language_template: str             # "Unlike solutions that..., our approach..."
    eval_criteria_link: str            # Which Section M factor this addresses
    subtlety_level: int = 3            # 1-5 (1=very subtle, 5=direct comparison)


class StrategyAgent:
    """
    The Strategy Agent - "The Capture Manager"
    
    Specialized in:
    - Evaluation factor analysis (Section M)
    - Win theme development
    - Competitor ghosting
    - Storyboarding and outline generation
    """
    
    def __init__(
        self,
        llm_client: Optional[Any] = None,
        past_performance_store: Optional[Any] = None,
        llm_provider: str = "gemini",
        use_llm: bool = True
    ):
        """
        Initialize the Strategy Agent

        Args:
            llm_client: LLM client for strategic reasoning (recommend Gemini Pro)
            past_performance_store: Vector store of past proposals for pattern matching
            llm_provider: Which LLM provider to use ("gemini", "anthropic", "openai")
            use_llm: If False, falls back to template-based generation
        """
        self.llm_client = llm_client
        self.past_performance_store = past_performance_store
        self.llm_provider = llm_provider
        self.use_llm = use_llm and HTTPX_AVAILABLE
        self._http_client = None

    def _get_http_client(self) -> Optional["httpx.Client"]:
        """Get or create HTTP client for LLM API calls"""
        if not HTTPX_AVAILABLE:
            return None
        if self._http_client is None:
            self._http_client = httpx.Client(timeout=60.0)
        return self._http_client

    def _call_llm(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """
        Call the LLM API for strategic reasoning.

        v4.0: Real LLM integration replacing template stubs.

        Args:
            prompt: The user prompt
            system_prompt: Optional system instructions

        Returns:
            LLM response text, or None if call fails
        """
        if not self.use_llm:
            return None

        client = self._get_http_client()
        if not client:
            return None

        provider_config = LLM_PROVIDERS.get(self.llm_provider, LLM_PROVIDERS["gemini"])
        api_key = os.environ.get(provider_config["env_key"])

        if not api_key:
            # Try fallback providers
            for fallback in ["gemini", "anthropic", "openai"]:
                if fallback == self.llm_provider:
                    continue
                fallback_config = LLM_PROVIDERS[fallback]
                api_key = os.environ.get(fallback_config["env_key"])
                if api_key:
                    provider_config = fallback_config
                    break

        if not api_key:
            return None

        try:
            if "gemini" in provider_config["model"]:
                return self._call_gemini(client, api_key, prompt, system_prompt, provider_config)
            elif "claude" in provider_config["model"]:
                return self._call_anthropic(client, api_key, prompt, system_prompt, provider_config)
            else:
                return self._call_openai(client, api_key, prompt, system_prompt, provider_config)
        except Exception as e:
            print(f"LLM call failed: {e}")
            return None

    def _call_gemini(
        self,
        client: "httpx.Client",
        api_key: str,
        prompt: str,
        system_prompt: Optional[str],
        config: Dict
    ) -> Optional[str]:
        """Call Gemini API"""
        url = f"{config['base_url']}/models/{config['model']}:generateContent?key={api_key}"

        contents = []
        if system_prompt:
            contents.append({"role": "user", "parts": [{"text": system_prompt}]})
            contents.append({"role": "model", "parts": [{"text": "Understood. I will follow these instructions."}]})
        contents.append({"role": "user", "parts": [{"text": prompt}]})

        response = client.post(
            url,
            json={
                "contents": contents,
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 4096,
                }
            }
        )

        if response.status_code == 200:
            data = response.json()
            candidates = data.get("candidates", [])
            if candidates:
                content = candidates[0].get("content", {})
                parts = content.get("parts", [])
                if parts:
                    return parts[0].get("text", "")
        return None

    def _call_anthropic(
        self,
        client: "httpx.Client",
        api_key: str,
        prompt: str,
        system_prompt: Optional[str],
        config: Dict
    ) -> Optional[str]:
        """Call Anthropic API"""
        url = f"{config['base_url']}/messages"

        headers = {
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json",
        }

        body = {
            "model": config["model"],
            "max_tokens": 4096,
            "messages": [{"role": "user", "content": prompt}],
        }

        if system_prompt:
            body["system"] = system_prompt

        response = client.post(url, headers=headers, json=body)

        if response.status_code == 200:
            data = response.json()
            content = data.get("content", [])
            if content:
                return content[0].get("text", "")
        return None

    def _call_openai(
        self,
        client: "httpx.Client",
        api_key: str,
        prompt: str,
        system_prompt: Optional[str],
        config: Dict
    ) -> Optional[str]:
        """Call OpenAI API"""
        url = f"{config['base_url']}/chat/completions"

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        response = client.post(
            url,
            headers=headers,
            json={
                "model": config["model"],
                "messages": messages,
                "max_tokens": 4096,
                "temperature": 0.7,
            }
        )

        if response.status_code == 200:
            data = response.json()
            choices = data.get("choices", [])
            if choices:
                return choices[0].get("message", {}).get("content", "")
        return None
        
    def __call__(self, state: ProposalState) -> Dict[str, Any]:
        """
        Main entry point - called by the Orchestrator
        
        Develops win strategy based on Section M and competitive landscape
        """
        start_time = datetime.now()
        
        # Get inputs from state
        evaluation_criteria = state.get("evaluation_criteria", [])
        requirements = state.get("requirements", [])
        instructions = state.get("instructions", [])
        rfp_metadata = state.get("rfp_metadata", {})
        
        if not evaluation_criteria:
            return {
                "error_state": "No evaluation criteria found - run compliance shred first",
                "agent_trace_log": [{
                    "timestamp": start_time.isoformat(),
                    "agent_name": "strategy_agent",
                    "action": "develop_strategy",
                    "input_summary": "Missing evaluation criteria",
                    "output_summary": "Error: Prerequisites not met",
                    "reasoning_trace": "Strategy requires Section M analysis from compliance shred"
                }]
            }
        
        # Phase 1: Analyze evaluation factors
        factor_analysis = self._analyze_evaluation_factors(evaluation_criteria)
        
        # Phase 2: Query past performance for winning patterns
        winning_patterns = self._query_winning_patterns(
            factor_analysis,
            rfp_metadata
        )
        
        # Phase 3: Develop win themes
        win_themes = self._develop_win_themes(
            factor_analysis,
            winning_patterns,
            requirements
        )
        
        # Phase 4: Competitor analysis (if data available)
        competitor_analysis = self._analyze_competitors(
            state.get("competitor_analysis", {}),
            factor_analysis
        )
        
        # Phase 5: Generate ghosting language
        for theme in win_themes:
            theme.ghosting_language = self._generate_ghosting(
                theme,
                competitor_analysis
            )
        
        # Phase 6: Create annotated outline with page allocations
        annotated_outline = self._create_annotated_outline(
            win_themes,
            requirements,
            instructions
        )
        
        # Calculate processing time
        duration_ms = int((datetime.now() - start_time).total_seconds() * 1000)
        
        # Build trace log
        trace_log = {
            "timestamp": start_time.isoformat(),
            "agent_name": "strategy_agent",
            "action": "develop_strategy",
            "input_summary": f"{len(evaluation_criteria)} eval criteria, {len(requirements)} requirements",
            "output_summary": f"Generated {len(win_themes)} win themes, {len(annotated_outline.get('volumes', {}))} volumes",
            "reasoning_trace": f"Primary factors: {', '.join(f['factor_name'] for f in factor_analysis[:3])}. "
                             f"Strategy framework: {self._determine_primary_framework(factor_analysis)}",
            "duration_ms": duration_ms,
            "tool_calls": [
                {"tool": "analyze_factors", "result": f"{len(factor_analysis)} factors analyzed"},
                {"tool": "query_patterns", "result": f"{len(winning_patterns)} patterns found"},
                {"tool": "develop_themes", "result": f"{len(win_themes)} themes generated"},
            ]
        }
        
        return {
            "current_phase": ProposalPhase.STRATEGY.value,
            "win_themes": [self._win_theme_to_dict(t) for t in win_themes],
            "competitor_analysis": competitor_analysis,
            "annotated_outline": annotated_outline,
            "agent_trace_log": [trace_log],
            "updated_at": datetime.now().isoformat()
        }
    
    def _analyze_evaluation_factors(
        self, 
        criteria: List[Dict]
    ) -> List[Dict[str, Any]]:
        """
        Analyze Section M evaluation factors to understand priorities
        
        Returns ranked list of factors with their relative importance
        """
        analyzed = []
        
        # Score importance based on weight and language
        for criterion in criteria:
            importance_score = 0.5  # Base score
            
            # Adjust for explicit weight
            if criterion.get("weight"):
                importance_score = criterion["weight"]
            
            # Adjust for language signals
            text_lower = criterion.get("text", "").lower()
            
            if "most important" in text_lower or "highest priority" in text_lower:
                importance_score = max(importance_score, 0.4)
            if "critical" in text_lower or "essential" in text_lower:
                importance_score += 0.1
            if "tradeoff" in text_lower:
                importance_score += 0.05  # Tradeoff factors are decision points
            
            analysis = {
                "criterion_id": criterion.get("id"),
                "factor_name": criterion.get("factor_name", "Unknown"),
                "text": criterion.get("text", ""),
                "importance_score": min(importance_score, 1.0),
                "key_phrases": self._extract_key_phrases(criterion.get("text", "")),
                "recommended_emphasis": self._recommend_emphasis(importance_score)
            }
            analyzed.append(analysis)
        
        # Sort by importance
        analyzed.sort(key=lambda x: x["importance_score"], reverse=True)
        
        return analyzed
    
    def _extract_key_phrases(self, text: str) -> List[str]:
        """Extract key phrases that evaluators will look for"""
        import re
        
        # Look for quoted requirements
        quoted = re.findall(r'"([^"]+)"', text)
        
        # Look for emphasized terms
        emphasized = []
        emphasis_patterns = [
            r'\b(must demonstrate|shall provide|is required)\b',
            r'\b(innovative|proven|comprehensive|detailed)\b',
            r'\b(risk mitigation|quality assurance|continuous improvement)\b'
        ]
        
        for pattern in emphasis_patterns:
            matches = re.findall(pattern, text.lower())
            emphasized.extend(matches)
        
        return list(set(quoted + emphasized))[:10]
    
    def _recommend_emphasis(self, importance_score: float) -> str:
        """Recommend level of emphasis in proposal"""
        if importance_score >= 0.35:
            return "PRIMARY - Dedicate significant page count and strongest evidence"
        elif importance_score >= 0.25:
            return "SECONDARY - Strong coverage required"
        elif importance_score >= 0.15:
            return "SUPPORTING - Adequate coverage with clear compliance"
        else:
            return "MINIMAL - Meet requirements, don't over-invest"
    
    def _query_winning_patterns(
        self, 
        factor_analysis: List[Dict],
        rfp_metadata: Dict
    ) -> List[Dict[str, Any]]:
        """
        Query the past performance store for winning patterns
        
        This is where the Data Flywheel kicks in - we learn from past wins
        """
        patterns = []
        
        # If we have a past performance store, query it
        if self.past_performance_store:
            # Query for similar opportunities
            query_text = " ".join([f["factor_name"] for f in factor_analysis])
            # results = self.past_performance_store.similarity_search(query_text)
            # patterns = self._extract_patterns(results)
            pass
        
        # Default patterns based on factor analysis
        primary_factors = [f["factor_name"] for f in factor_analysis[:3]]
        
        if "Technical Approach" in primary_factors:
            patterns.append({
                "pattern_name": "Technical Depth Strategy",
                "description": "Lead with technical innovation and detailed methodology",
                "success_rate": 0.72,
                "key_elements": [
                    "Detailed technical approach with diagrams",
                    "Innovation features highlighted",
                    "Risk identification with mitigation"
                ]
            })
        
        if "Past Performance" in primary_factors:
            patterns.append({
                "pattern_name": "Relevance Mapping Strategy",
                "description": "Map past contracts directly to current requirements",
                "success_rate": 0.68,
                "key_elements": [
                    "Direct requirement-to-experience mapping",
                    "Quantified results and metrics",
                    "Customer references ready"
                ]
            })
        
        if "Management Approach" in primary_factors:
            patterns.append({
                "pattern_name": "Transition Risk Mitigation",
                "description": "Emphasize seamless transition and execution certainty",
                "success_rate": 0.65,
                "key_elements": [
                    "Detailed transition plan",
                    "Key personnel committed",
                    "QA/QC processes documented"
                ]
            })
        
        if "Price/Cost" in primary_factors:
            patterns.append({
                "pattern_name": "Best Value Positioning",
                "description": "Demonstrate value, not just low price",
                "success_rate": 0.58,
                "key_elements": [
                    "Total cost of ownership analysis",
                    "Efficiency gains quantified",
                    "Investment in contract startup"
                ]
            })
        
        return patterns
    
    def _develop_win_themes(
        self,
        factor_analysis: List[Dict],
        winning_patterns: List[Dict],
        requirements: List[Dict]
    ) -> List[WinTheme]:
        """
        Develop win themes based on analysis.

        v4.0: Uses LLM for intelligent theme generation when available,
        falls back to template-based generation otherwise.

        Each theme should:
        - Address a primary evaluation factor
        - Be unique/differentiated
        - Have provable evidence
        """
        # Try LLM-based theme generation first
        if self.use_llm:
            llm_themes = self._generate_themes_with_llm(factor_analysis, winning_patterns, requirements)
            if llm_themes:
                return llm_themes

        # Fallback to template-based generation
        return self._generate_themes_from_templates(factor_analysis, winning_patterns, requirements)

    def _generate_themes_with_llm(
        self,
        factor_analysis: List[Dict],
        winning_patterns: List[Dict],
        requirements: List[Dict]
    ) -> Optional[List[WinTheme]]:
        """
        Generate win themes using LLM.

        v4.0: Real strategic reasoning via LLM.
        """
        system_prompt = """You are an expert federal proposal strategist with 20+ years of experience winning government contracts.

Your task is to develop win themes that will resonate with government evaluators.

For each evaluation factor, create a win theme that:
1. Directly addresses what the government cares about most
2. Differentiates from competitors without naming them
3. Is provable with evidence (past performance, case studies, metrics)
4. Uses action-oriented, benefit-focused language

Output your themes in this exact JSON format:
{
  "themes": [
    {
      "factor_name": "Technical Approach",
      "headline": "One powerful sentence that captures why we win",
      "narrative": "2-3 sentences expanding on the headline with specific benefits",
      "discriminator_claim": "Specific claim that sets us apart (with quantification if possible)",
      "discriminator_type": "technical|management|past_performance|price|innovation|risk|personnel",
      "proof_points": ["Evidence point 1", "Evidence point 2", "Evidence point 3"],
      "ghosting_angle": "Subtle language to position against competitors without naming them",
      "priority": 1
    }
  ]
}"""

        # Build the prompt with context
        factors_text = "\n".join([
            f"- {f['factor_name']} (importance: {f['importance_score']:.0%}): {f['text'][:200]}..."
            for f in factor_analysis[:5]
        ])

        patterns_text = "\n".join([
            f"- {p['pattern_name']}: {p['description']}"
            for p in winning_patterns[:3]
        ]) if winning_patterns else "No historical patterns available."

        req_sample = "\n".join([
            f"- {r.get('text', '')[:100]}..."
            for r in requirements[:10]
        ]) if requirements else "No requirements provided."

        prompt = f"""Analyze these evaluation factors and develop win themes:

EVALUATION FACTORS (from Section M):
{factors_text}

HISTORICAL WINNING PATTERNS:
{patterns_text}

SAMPLE REQUIREMENTS TO ADDRESS:
{req_sample}

Generate 3-5 win themes that will score highest with government evaluators. Focus on the most important factors first.

Return ONLY valid JSON matching the schema above."""

        response = self._call_llm(prompt, system_prompt)
        if not response:
            return None

        # Parse JSON response
        try:
            # Extract JSON from response (handle markdown code blocks)
            json_match = re.search(r'\{[\s\S]*\}', response)
            if not json_match:
                return None

            data = json.loads(json_match.group())
            themes_data = data.get("themes", [])

            themes = []
            for i, t in enumerate(themes_data):
                # Determine discriminator type
                disc_type_str = t.get("discriminator_type", "technical").lower()
                try:
                    disc_type = DiscriminatorType(disc_type_str)
                except ValueError:
                    disc_type = DiscriminatorType.TECHNICAL

                discriminator = Discriminator(
                    id=f"DISC-{i+1:02d}",
                    category=disc_type,
                    claim=t.get("discriminator_claim", ""),
                    evidence_type="case_study",
                    evidence_source=None,
                    quantified_impact=None,
                    ghosting_angle=t.get("ghosting_angle"),
                )

                theme = WinTheme(
                    id=f"THEME-{i+1:02d}",
                    theme_headline=t.get("headline", ""),
                    theme_narrative=t.get("narrative", ""),
                    discriminators=[discriminator],
                    proof_points=t.get("proof_points", []),
                    linked_eval_criteria=[t.get("factor_name", "")],
                    ghosting_language=t.get("ghosting_angle"),
                    priority=t.get("priority", i + 1),
                    confidence=0.8,
                    llm_generated=True,
                )
                themes.append(theme)

            return themes if themes else None

        except (json.JSONDecodeError, KeyError, TypeError) as e:
            print(f"Failed to parse LLM theme response: {e}")
            return None

    def _generate_themes_from_templates(
        self,
        factor_analysis: List[Dict],
        winning_patterns: List[Dict],
        requirements: List[Dict]
    ) -> List[WinTheme]:
        """
        Template-based theme generation (fallback when LLM unavailable).
        """
        themes = []

        for i, factor in enumerate(factor_analysis[:5]):
            factor_name = factor["factor_name"]

            # Find relevant pattern
            relevant_pattern = next(
                (p for p in winning_patterns
                 if any(kw in p["pattern_name"].lower()
                       for kw in factor_name.lower().split())),
                None
            )

            # Generate theme headline
            headline = self._generate_theme_text(factor, relevant_pattern)

            # Generate discriminator
            disc_claim = self._generate_discriminator_claim(factor)
            disc_type = self._infer_discriminator_type(factor_name)

            discriminator = Discriminator(
                id=f"DISC-{i+1:02d}",
                category=disc_type,
                claim=disc_claim,
                evidence_type="case_study",
                evidence_source=None,
                quantified_impact=None,
                ghosting_angle=None,
            )

            theme = WinTheme(
                id=f"THEME-{i+1:02d}",
                theme_headline=headline,
                theme_narrative=f"Our approach to {factor_name.lower()} demonstrates proven capabilities that directly address your mission requirements.",
                discriminators=[discriminator],
                proof_points=self._generate_proof_points(factor, requirements),
                linked_eval_criteria=[factor["criterion_id"]] if factor.get("criterion_id") else [],
                ghosting_language=None,
                priority=i + 1,
                confidence=factor["importance_score"],
                llm_generated=False,
            )
            themes.append(theme)

        return themes

    def _infer_discriminator_type(self, factor_name: str) -> DiscriminatorType:
        """Infer discriminator type from factor name"""
        factor_lower = factor_name.lower()
        if "technical" in factor_lower:
            return DiscriminatorType.TECHNICAL
        elif "management" in factor_lower:
            return DiscriminatorType.MANAGEMENT
        elif "past" in factor_lower or "performance" in factor_lower:
            return DiscriminatorType.PAST_PERFORMANCE
        elif "price" in factor_lower or "cost" in factor_lower:
            return DiscriminatorType.PRICE
        elif "staff" in factor_lower or "personnel" in factor_lower:
            return DiscriminatorType.PERSONNEL
        elif "risk" in factor_lower:
            return DiscriminatorType.RISK
        else:
            return DiscriminatorType.TECHNICAL

    def _generate_discriminator_claim(self, factor: Dict) -> str:
        """Generate discriminator claim (legacy compatibility)"""
        return self._generate_discriminator(factor)
    
    def _generate_theme_text(
        self, 
        factor: Dict, 
        pattern: Optional[Dict]
    ) -> str:
        """Generate the headline theme text"""
        factor_name = factor["factor_name"]
        
        # Theme templates by factor type
        templates = {
            "Technical Approach": [
                "Proven Technical Excellence Delivered Through Innovation",
                "Mission-Focused Technical Solutions Built on Experience",
                "Accelerated Results Through Proven Methodology"
            ],
            "Management Approach": [
                "Seamless Transition Through Experienced Leadership",
                "Risk-Mitigated Execution From Day One",
                "Proven Management Framework Ensures Success"
            ],
            "Past Performance": [
                "Demonstrated Success in Identical Mission Environments",
                "Track Record of Excellence with Government Customers",
                "Proven Past Performance Directly Relevant to Your Mission"
            ],
            "Price/Cost": [
                "Best Value Through Operational Efficiency",
                "Cost-Effective Solutions Without Compromising Quality",
                "Transparent Pricing with Maximum ROI"
            ],
            "Staffing/Key Personnel": [
                "Mission-Ready Team with Proven Expertise",
                "Committed Key Personnel with Direct Experience",
                "Expert Staff Immediately Available for Transition"
            ]
        }
        
        # Get appropriate template
        if factor_name in templates:
            return templates[factor_name][0]
        else:
            return f"Excellence in {factor_name} Through Proven Capabilities"
    
    def _generate_discriminator(self, factor: Dict) -> str:
        """Generate the unique discriminator"""
        factor_name = factor["factor_name"]
        
        discriminators = {
            "Technical Approach": "Our proprietary methodology reduces implementation risk by 40%",
            "Management Approach": "Zero-defect transition record across 15 similar contracts",
            "Past Performance": "Direct relevant experience with same agency mission",
            "Price/Cost": "Lean operations model delivers 15% cost savings",
            "Staffing/Key Personnel": "All key personnel have current security clearances"
        }
        
        return discriminators.get(factor_name, f"Differentiated approach to {factor_name}")
    
    def _generate_proof_points(
        self, 
        factor: Dict, 
        requirements: List[Dict]
    ) -> List[str]:
        """Generate evidence points to support the theme"""
        proof_points = []
        
        # Get key phrases from the factor
        key_phrases = factor.get("key_phrases", [])
        
        # Match requirements that could provide evidence
        for req in requirements[:20]:  # Sample first 20
            req_keywords = req.get("keywords", [])
            if any(kp.lower() in " ".join(req_keywords).lower() for kp in key_phrases):
                proof_points.append(f"Directly addresses: {req.get('section_ref', 'requirement')}")
        
        # Add generic proof point templates
        factor_name = factor["factor_name"]
        
        if factor_name == "Technical Approach":
            proof_points.extend([
                "Technical approach diagram in Section X.X",
                "Innovation feature addresses Section C requirement",
                "Risk mitigation matrix demonstrates proactive planning"
            ])
        elif factor_name == "Past Performance":
            proof_points.extend([
                "Contract ABC123 - Same scope, same customer",
                "Quantified metrics: 99.9% uptime achieved",
                "CPARs rating: Exceptional"
            ])
        
        return proof_points[:5]  # Limit to 5 proof points per theme
    
    def _analyze_competitors(
        self, 
        competitor_data: Dict,
        factor_analysis: List[Dict]
    ) -> Dict[str, Any]:
        """Analyze competitive landscape"""
        analysis = {
            "competitors_identified": [],
            "competitive_gaps": [],
            "win_probability_factors": []
        }
        
        # If competitor data provided
        if competitor_data.get("competitors"):
            for comp in competitor_data["competitors"]:
                profile = CompetitorProfile(
                    name=comp.get("name", "Unknown"),
                    strengths=comp.get("strengths", []),
                    weaknesses=comp.get("weaknesses", []),
                    likely_themes=self._predict_competitor_themes(comp, factor_analysis),
                    ghosting_opportunities=self._identify_ghosting_ops(comp)
                )
                analysis["competitors_identified"].append({
                    "name": profile.name,
                    "strengths": profile.strengths,
                    "weaknesses": profile.weaknesses,
                    "likely_themes": profile.likely_themes,
                    "ghosting_opportunities": profile.ghosting_opportunities
                })
        
        return analysis
    
    def _predict_competitor_themes(
        self, 
        competitor: Dict, 
        factors: List[Dict]
    ) -> List[str]:
        """Predict what themes a competitor will likely use"""
        themes = []
        
        strengths = competitor.get("strengths", [])
        
        if "incumbent" in " ".join(strengths).lower():
            themes.append("Leverage existing knowledge and relationships")
        if "large" in " ".join(strengths).lower():
            themes.append("Emphasize resources and stability")
        if "technical" in " ".join(strengths).lower():
            themes.append("Lead with technical capabilities")
        
        return themes
    
    def _identify_ghosting_ops(self, competitor: Dict) -> List[str]:
        """Identify opportunities to ghost (de-position) competitor"""
        opportunities = []
        
        weaknesses = competitor.get("weaknesses", [])
        
        for weakness in weaknesses:
            weakness_lower = weakness.lower()
            
            if "transition" in weakness_lower or "new" in weakness_lower:
                opportunities.append(
                    "Emphasize our proven transition capability and low risk"
                )
            if "size" in weakness_lower or "small" in weakness_lower:
                opportunities.append(
                    "Highlight our scalable resources and financial stability"
                )
            if "experience" in weakness_lower:
                opportunities.append(
                    "Demonstrate directly relevant past performance"
                )
        
        return opportunities
    
    def _generate_ghosting(
        self, 
        theme: WinTheme, 
        competitor_analysis: Dict
    ) -> Optional[str]:
        """Generate ghosting language for a theme"""
        # Generic ghosting that doesn't name competitors but addresses gaps
        ghosting_templates = {
            "Technical Approach": 
                "Unlike generic approaches, our methodology is specifically "
                "designed for government environments with built-in security.",
            "Management Approach":
                "Our management team brings hands-on agency experience, "
                "not just theoretical knowledge of government operations.",
            "Past Performance":
                "We offer directly relevant recent past performance, "
                "not outdated or tangentially related contract experience.",
            "Price/Cost":
                "Our pricing reflects realistic staffing and efficient operations, "
                "not underbidding that leads to performance issues."
        }
        
        # Match theme to ghosting
        for factor, ghosting in ghosting_templates.items():
            if factor.lower() in theme.theme_text.lower():
                return ghosting
        
        return None
    
    def _create_annotated_outline(
        self,
        win_themes: List[WinTheme],
        requirements: List[Dict],
        instructions: List[Dict]
    ) -> Dict[str, Any]:
        """
        Create the annotated outline (storyboard)
        
        Maps sections to requirements, themes, and page allocations
        """
        # Extract page limits from instructions
        total_pages = 100  # Default
        for inst in instructions:
            if inst.get("page_limit"):
                total_pages = inst["page_limit"]
                break
        
        # Standard federal proposal structure
        outline = {
            "total_page_limit": total_pages,
            "volumes": {
                "volume_1_technical": {
                    "title": "Technical Volume",
                    "page_allocation": int(total_pages * 0.5),
                    "sections": []
                },
                "volume_2_management": {
                    "title": "Management Volume", 
                    "page_allocation": int(total_pages * 0.25),
                    "sections": []
                },
                "volume_3_past_performance": {
                    "title": "Past Performance Volume",
                    "page_allocation": int(total_pages * 0.15),
                    "sections": []
                },
                "volume_4_pricing": {
                    "title": "Pricing Volume",
                    "page_allocation": int(total_pages * 0.1),
                    "sections": []
                }
            }
        }
        
        # Populate technical volume sections with themes
        tech_themes = [t for t in win_themes if "technical" in t.theme_text.lower()]
        for i, theme in enumerate(tech_themes):
            outline["volumes"]["volume_1_technical"]["sections"].append({
                "section_number": f"1.{i+1}",
                "title": f"Technical Approach - {theme.discriminator[:50]}",
                "win_theme": theme.theme_text,
                "discriminator": theme.discriminator,
                "page_allocation": 10,
                "linked_requirements": theme.linked_criteria,
                "proof_points": theme.proof_points
            })
        
        # Add default sections if no themes
        if not outline["volumes"]["volume_1_technical"]["sections"]:
            outline["volumes"]["volume_1_technical"]["sections"] = [
                {"section_number": "1.1", "title": "Technical Approach Overview", "page_allocation": 15},
                {"section_number": "1.2", "title": "Methodology", "page_allocation": 20},
                {"section_number": "1.3", "title": "Innovation", "page_allocation": 10},
                {"section_number": "1.4", "title": "Risk Management", "page_allocation": 5}
            ]
        
        # Management volume
        outline["volumes"]["volume_2_management"]["sections"] = [
            {"section_number": "2.1", "title": "Management Approach", "page_allocation": 8},
            {"section_number": "2.2", "title": "Transition Plan", "page_allocation": 7},
            {"section_number": "2.3", "title": "Quality Assurance", "page_allocation": 5},
            {"section_number": "2.4", "title": "Staffing Plan", "page_allocation": 5}
        ]
        
        # Past Performance volume
        outline["volumes"]["volume_3_past_performance"]["sections"] = [
            {"section_number": "3.1", "title": "Relevant Contract 1", "page_allocation": 5},
            {"section_number": "3.2", "title": "Relevant Contract 2", "page_allocation": 5},
            {"section_number": "3.3", "title": "Relevant Contract 3", "page_allocation": 5}
        ]
        
        return outline
    
    def _determine_primary_framework(self, factor_analysis: List[Dict]) -> str:
        """Determine the primary strategy framework based on factors"""
        if not factor_analysis:
            return StrategyFramework.TECHNICAL_EXCELLENCE.value
        
        top_factor = factor_analysis[0]["factor_name"]
        
        framework_map = {
            "Technical Approach": StrategyFramework.TECHNICAL_EXCELLENCE,
            "Past Performance": StrategyFramework.PAST_PERFORMANCE,
            "Price/Cost": StrategyFramework.PRICE_TO_WIN,
            "Management Approach": StrategyFramework.RISK_MITIGATION,
        }
        
        return framework_map.get(top_factor, StrategyFramework.TECHNICAL_EXCELLENCE).value
    
    def _win_theme_to_dict(self, theme: WinTheme) -> Dict[str, Any]:
        """Convert WinTheme to dictionary for state storage"""
        return {
            "id": theme.id,
            # v4.0 fields
            "theme_headline": theme.theme_headline,
            "theme_narrative": theme.theme_narrative,
            "discriminators": [
                {
                    "id": d.id,
                    "category": d.category.value,
                    "claim": d.claim,
                    "evidence_type": d.evidence_type,
                    "evidence_source": d.evidence_source,
                    "quantified_impact": d.quantified_impact,
                    "ghosting_angle": d.ghosting_angle,
                }
                for d in theme.discriminators
            ],
            "proof_points": theme.proof_points,
            "linked_eval_criteria": theme.linked_eval_criteria,
            "ghosting_language": theme.ghosting_language,
            "page_allocation_percent": theme.page_allocation_percent,
            "priority": theme.priority,
            "confidence": theme.confidence,
            "llm_generated": theme.llm_generated,
            # Legacy compatibility
            "theme_text": theme.theme_text,
            "discriminator": theme.discriminator,
            "linked_criteria": theme.linked_criteria,
        }


# ============================================================================
# v4.0: Ghosting Language Generator (Task 2.2.3)
# ============================================================================

class GhostingLanguageGenerator:
    """
    v4.0: Generates subtle competitive positioning language.

    Ghosting is the art of positioning against competitors without
    naming them directly. Good ghosting:
    - Highlights our strengths in areas where competitors are weak
    - Uses positive framing ("We offer X" not "They lack X")
    - Aligns with evaluation criteria
    - Is subtle enough to pass legal/ethical review
    """

    # Ghosting templates by weakness category
    GHOSTING_TEMPLATES = {
        "experience": {
            "weakness_pattern": ["new", "limited experience", "lack", "first time"],
            "our_strength": "directly relevant experience",
            "templates": [
                "Our team brings {years}+ years of directly relevant experience, ensuring mission continuity from day one.",
                "Unlike approaches based on theoretical knowledge, our methodology is battle-tested across {count} similar contracts.",
                "We offer proven past performance with the same customer base, not aspirational claims.",
            ]
        },
        "transition_risk": {
            "weakness_pattern": ["transition", "startup", "ramp", "learning curve"],
            "our_strength": "seamless transition",
            "templates": [
                "Our zero-defect transition track record eliminates startup risk and ensures continuous operations.",
                "Rather than extended learning curves, we deliver Day 1 readiness through our proven onboarding process.",
                "Our incumbent-like knowledge eliminates the transition gaps that often plague new contractors.",
            ]
        },
        "scale": {
            "weakness_pattern": ["small", "limited resources", "capacity", "scale"],
            "our_strength": "enterprise scale",
            "templates": [
                "Our enterprise-scale resources ensure we can flex to meet surge requirements without compromising quality.",
                "Unlike capacity-constrained alternatives, our nationwide bench provides immediate access to cleared talent.",
                "Our financial stability ensures uninterrupted service delivery throughout the contract lifecycle.",
            ]
        },
        "innovation": {
            "weakness_pattern": ["legacy", "outdated", "traditional", "conventional"],
            "our_strength": "modern innovation",
            "templates": [
                "Our modern, cloud-native approach delivers capabilities that legacy systems cannot match.",
                "We bring innovation without risk—proven technologies already successfully deployed in similar environments.",
                "Our forward-leaning technical approach positions you for future requirements, not just today's needs.",
            ]
        },
        "personnel": {
            "weakness_pattern": ["staff", "personnel", "turnover", "retention"],
            "our_strength": "committed personnel",
            "templates": [
                "Our named key personnel have committed to this contract, ensuring continuity and accountability.",
                "With industry-leading retention rates of {retention}%, we deliver consistent service quality.",
                "All proposed staff hold current {clearance} clearances—no delays, no substitutions.",
            ]
        },
        "price_realism": {
            "weakness_pattern": ["low price", "underbid", "unrealistic", "buy-in"],
            "our_strength": "realistic pricing",
            "templates": [
                "Our pricing reflects realistic labor categories and proven efficiency—not optimistic assumptions.",
                "We invest in contract success upfront, avoiding the performance issues that plague underbid contracts.",
                "Our cost model is built on actual performance data, ensuring sustainable service delivery.",
            ]
        },
        "technical_depth": {
            "weakness_pattern": ["generic", "superficial", "boilerplate", "off-the-shelf"],
            "our_strength": "tailored solution",
            "templates": [
                "Our solution is purpose-built for your mission, not adapted from a generic commercial offering.",
                "Every aspect of our technical approach addresses your specific requirements—no boilerplate.",
                "We bring deep domain expertise in {domain}, not surface-level familiarity.",
            ]
        },
    }

    def __init__(self, use_llm: bool = True, llm_caller: Optional[callable] = None):
        """
        Initialize the ghosting generator.

        Args:
            use_llm: Whether to use LLM for generation (enhances templates)
            llm_caller: Optional function to call LLM (signature: prompt -> str)
        """
        self.use_llm = use_llm
        self.llm_caller = llm_caller

    def generate_ghosting_library(
        self,
        win_themes: List[WinTheme],
        competitor_weaknesses: List[str],
        eval_criteria: List[Dict]
    ) -> List[GhostingStrategy]:
        """
        Generate a library of ghosting language for the proposal.

        Args:
            win_themes: Our win themes to reinforce
            competitor_weaknesses: Known/suspected competitor weaknesses
            eval_criteria: Evaluation criteria to align with

        Returns:
            List of GhostingStrategy objects ready for integration
        """
        strategies = []

        for weakness in competitor_weaknesses:
            weakness_lower = weakness.lower()

            # Find matching template category
            for category, config in self.GHOSTING_TEMPLATES.items():
                if any(pattern in weakness_lower for pattern in config["weakness_pattern"]):
                    # Find aligned evaluation criterion
                    aligned_criterion = self._find_aligned_criterion(
                        category, eval_criteria
                    )

                    # Select best template
                    template = self._select_template(
                        config["templates"],
                        win_themes,
                        weakness
                    )

                    strategy = GhostingStrategy(
                        competitor_weakness=weakness,
                        our_strength=config["our_strength"],
                        language_template=template,
                        eval_criteria_link=aligned_criterion,
                        subtlety_level=3
                    )
                    strategies.append(strategy)
                    break

        # Try LLM enhancement if available
        if self.use_llm and self.llm_caller and strategies:
            enhanced = self._enhance_with_llm(strategies, win_themes)
            if enhanced:
                strategies = enhanced

        return strategies

    def generate_for_section(
        self,
        section_type: str,
        our_discriminators: List[Discriminator],
        competitor_profile: Optional[CompetitorProfile] = None
    ) -> List[str]:
        """
        Generate ghosting language for a specific proposal section.

        Args:
            section_type: "technical", "management", "past_performance", etc.
            our_discriminators: Our discriminators to reinforce
            competitor_profile: Optional specific competitor to ghost

        Returns:
            List of ghosting sentences ready to weave into content
        """
        sentences = []

        # Section-specific ghosting
        section_ghosts = {
            "technical": [
                "Our approach is specifically designed for {domain} environments, not adapted from commercial solutions.",
                "We integrate proven technologies that eliminate the risks associated with experimental approaches.",
            ],
            "management": [
                "Our management team has direct experience with {agency}, not just theoretical familiarity.",
                "We provide named, committed key personnel—not placeholder positions to be filled post-award.",
            ],
            "past_performance": [
                "Our past performance is directly relevant to this requirement, not tangentially related.",
                "We offer recent, verifiable results with current customer references.",
            ],
            "transition": [
                "Our transition approach is based on proven playbooks, not first-time execution.",
                "We eliminate transition risk through incumbency-level knowledge and ready personnel.",
            ],
        }

        base_ghosts = section_ghosts.get(section_type.lower(), [])
        sentences.extend(base_ghosts)

        # Add discriminator-based ghosting
        for disc in our_discriminators:
            if disc.ghosting_angle:
                sentences.append(disc.ghosting_angle)

        # Add competitor-specific ghosting if provided
        if competitor_profile and competitor_profile.weaknesses:
            for weakness in competitor_profile.weaknesses[:3]:
                ghost = self._generate_single_ghost(weakness, section_type)
                if ghost:
                    sentences.append(ghost)

        return sentences[:5]  # Limit to avoid over-ghosting

    def _find_aligned_criterion(
        self,
        category: str,
        eval_criteria: List[Dict]
    ) -> str:
        """Find evaluation criterion that aligns with ghosting category"""
        category_to_criteria = {
            "experience": ["past performance", "experience", "relevant"],
            "transition_risk": ["management", "transition", "risk"],
            "scale": ["resources", "capacity", "staffing"],
            "innovation": ["technical", "approach", "solution"],
            "personnel": ["staffing", "key personnel", "qualifications"],
            "price_realism": ["price", "cost", "value"],
            "technical_depth": ["technical", "approach", "methodology"],
        }

        keywords = category_to_criteria.get(category, [])

        for criterion in eval_criteria:
            criterion_text = criterion.get("factor_name", "").lower()
            if any(kw in criterion_text for kw in keywords):
                return criterion.get("criterion_id", criterion.get("factor_name", ""))

        return ""

    def _select_template(
        self,
        templates: List[str],
        win_themes: List[WinTheme],
        weakness: str
    ) -> str:
        """Select and customize the best template"""
        # Simple selection - first template that matches context
        template = templates[0]

        # Basic variable substitution
        template = template.replace("{years}", "15")
        template = template.replace("{count}", "12")
        template = template.replace("{retention}", "95")
        template = template.replace("{clearance}", "TS/SCI")
        template = template.replace("{domain}", "government IT")
        template = template.replace("{agency}", "the customer")

        return template

    def _generate_single_ghost(self, weakness: str, section_type: str) -> Optional[str]:
        """Generate a single ghosting sentence for a specific weakness"""
        weakness_lower = weakness.lower()

        for category, config in self.GHOSTING_TEMPLATES.items():
            if any(pattern in weakness_lower for pattern in config["weakness_pattern"]):
                template = config["templates"][0]
                return self._select_template([template], [], weakness)

        return None

    def _enhance_with_llm(
        self,
        strategies: List[GhostingStrategy],
        win_themes: List[WinTheme]
    ) -> Optional[List[GhostingStrategy]]:
        """Enhance ghosting with LLM"""
        if not self.llm_caller:
            return None

        prompt = f"""Enhance these ghosting statements to be more subtle and persuasive while maintaining professional tone.

CURRENT GHOSTING STRATEGIES:
{json.dumps([{"weakness": s.competitor_weakness, "template": s.language_template} for s in strategies], indent=2)}

WIN THEMES TO REINFORCE:
{json.dumps([t.theme_headline for t in win_themes], indent=2)}

Requirements:
1. Make language more subtle (never name competitors)
2. Focus on positive framing ("We offer..." not "They lack...")
3. Align with government proposal writing standards
4. Keep each statement to 1-2 sentences

Return enhanced statements in JSON format:
{{"enhanced": [{{"weakness": "...", "statement": "..."}}]}}
"""

        try:
            response = self.llm_caller(prompt)
            if response:
                data = json.loads(re.search(r'\{[\s\S]*\}', response).group())
                enhanced_list = data.get("enhanced", [])

                for i, item in enumerate(enhanced_list):
                    if i < len(strategies):
                        strategies[i].language_template = item.get("statement", strategies[i].language_template)

                return strategies
        except Exception:
            pass

        return None


# ============================================================================
# v4.0: Competitor Analyzer (Task 2.3.1)
# ============================================================================

class CompetitorAnalyzer:
    """
    v4.0: Analyzes competitive landscape for strategic positioning.

    Capabilities:
    - Profile known/likely competitors
    - Identify competitor strengths and weaknesses
    - Predict competitor themes and strategies
    - Generate ghosting opportunities
    """

    def __init__(self, use_llm: bool = True, llm_caller: Optional[callable] = None):
        """
        Initialize the competitor analyzer.

        Args:
            use_llm: Whether to use LLM for analysis
            llm_caller: Optional function to call LLM
        """
        self.use_llm = use_llm
        self.llm_caller = llm_caller
        self.ghosting_generator = GhostingLanguageGenerator(use_llm, llm_caller)

    def analyze_competitive_landscape(
        self,
        rfp_data: Dict,
        known_competitors: Optional[List[Dict]] = None,
        market_intel: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Perform comprehensive competitive analysis.

        Args:
            rfp_data: RFP information including requirements and eval criteria
            known_competitors: Optional list of known competitor data
            market_intel: Optional market intelligence

        Returns:
            Comprehensive competitive analysis
        """
        analysis = {
            "competitor_profiles": [],
            "competitive_gaps": [],
            "ghosting_library": [],
            "win_probability_factors": [],
            "recommended_positioning": [],
        }

        # Analyze known competitors
        if known_competitors:
            for comp_data in known_competitors:
                profile = self._build_competitor_profile(comp_data, rfp_data)
                analysis["competitor_profiles"].append(profile)

        # Identify competitive gaps (opportunities)
        analysis["competitive_gaps"] = self._identify_gaps(
            analysis["competitor_profiles"],
            rfp_data.get("requirements", [])
        )

        # Generate ghosting library
        all_weaknesses = []
        for profile in analysis["competitor_profiles"]:
            all_weaknesses.extend(profile.get("weaknesses", []))

        if all_weaknesses:
            eval_criteria = rfp_data.get("evaluation_criteria", [])
            analysis["ghosting_library"] = [
                self._ghosting_to_dict(gs)
                for gs in self.ghosting_generator.generate_ghosting_library(
                    [],  # Win themes not yet generated
                    all_weaknesses,
                    eval_criteria
                )
            ]

        # Calculate win probability factors
        analysis["win_probability_factors"] = self._calculate_win_factors(
            analysis["competitor_profiles"],
            rfp_data
        )

        # Generate recommended positioning
        analysis["recommended_positioning"] = self._generate_positioning(
            analysis["competitive_gaps"],
            rfp_data.get("evaluation_criteria", [])
        )

        return analysis

    def _build_competitor_profile(
        self,
        comp_data: Dict,
        rfp_data: Dict
    ) -> Dict[str, Any]:
        """Build a detailed competitor profile"""
        profile = {
            "name": comp_data.get("name", "Unknown Competitor"),
            "is_incumbent": comp_data.get("is_incumbent", False),
            "strengths": comp_data.get("strengths", []),
            "weaknesses": comp_data.get("weaknesses", []),
            "likely_themes": [],
            "threat_level": "medium",
            "ghosting_opportunities": [],
        }

        # Predict likely themes
        profile["likely_themes"] = self._predict_themes(comp_data, rfp_data)

        # Assess threat level
        profile["threat_level"] = self._assess_threat(comp_data, rfp_data)

        # Identify ghosting opportunities
        for weakness in profile["weaknesses"]:
            opp = self._weakness_to_opportunity(weakness)
            if opp:
                profile["ghosting_opportunities"].append(opp)

        return profile

    def _predict_themes(self, comp_data: Dict, rfp_data: Dict) -> List[str]:
        """Predict competitor's likely win themes"""
        themes = []
        strengths = comp_data.get("strengths", [])
        strengths_text = " ".join(strengths).lower()

        # Theme prediction based on strengths
        if "incumbent" in strengths_text:
            themes.append("Leverage existing relationships and institutional knowledge")
        if "large" in strengths_text or "enterprise" in strengths_text:
            themes.append("Emphasize resources and stability")
        if "technical" in strengths_text or "innovation" in strengths_text:
            themes.append("Lead with technical differentiation")
        if "price" in strengths_text or "cost" in strengths_text:
            themes.append("Compete on price competitiveness")
        if "local" in strengths_text or "small business" in strengths_text:
            themes.append("Position as agile small business partner")

        return themes if themes else ["Generic best value approach"]

    def _assess_threat(self, comp_data: Dict, rfp_data: Dict) -> str:
        """Assess competitor threat level"""
        score = 0

        if comp_data.get("is_incumbent"):
            score += 3

        strengths = comp_data.get("strengths", [])
        weaknesses = comp_data.get("weaknesses", [])

        score += len(strengths) * 0.5
        score -= len(weaknesses) * 0.3

        if score >= 4:
            return "high"
        elif score >= 2:
            return "medium"
        else:
            return "low"

    def _weakness_to_opportunity(self, weakness: str) -> Optional[str]:
        """Convert competitor weakness to ghosting opportunity"""
        weakness_lower = weakness.lower()

        opportunities = {
            "transition": "Emphasize our proven transition capability and Day 1 readiness",
            "experience": "Highlight our directly relevant past performance",
            "size": "Demonstrate our scalable resources and financial stability",
            "turnover": "Feature our committed, named personnel with retention track record",
            "price": "Position our realistic, sustainable pricing model",
            "technology": "Showcase our modern, proven technical approach",
        }

        for keyword, opp in opportunities.items():
            if keyword in weakness_lower:
                return opp

        return None

    def _identify_gaps(
        self,
        profiles: List[Dict],
        requirements: List[Dict]
    ) -> List[Dict]:
        """Identify gaps in competitive landscape we can exploit"""
        gaps = []

        # Collect all competitor weaknesses
        all_weaknesses = []
        for profile in profiles:
            all_weaknesses.extend(profile.get("weaknesses", []))

        # Find common weaknesses (opportunities for us)
        weakness_counts = {}
        for w in all_weaknesses:
            key = w.lower()[:20]
            weakness_counts[key] = weakness_counts.get(key, 0) + 1

        for weakness, count in weakness_counts.items():
            if count >= 2:  # Multiple competitors share this weakness
                gaps.append({
                    "gap_type": "common_weakness",
                    "description": f"Multiple competitors weak in: {weakness}",
                    "opportunity": f"Strongly emphasize our strength in this area",
                    "competitor_count": count
                })

        return gaps

    def _calculate_win_factors(
        self,
        profiles: List[Dict],
        rfp_data: Dict
    ) -> List[Dict]:
        """Calculate factors affecting win probability"""
        factors = []

        # Incumbent presence
        incumbents = [p for p in profiles if p.get("is_incumbent")]
        if incumbents:
            factors.append({
                "factor": "Incumbent Competition",
                "impact": "negative",
                "weight": 0.3,
                "mitigation": "Emphasize fresh perspective and innovation",
            })
        else:
            factors.append({
                "factor": "No Strong Incumbent",
                "impact": "positive",
                "weight": 0.2,
                "action": "Position as most qualified with low transition risk",
            })

        # Competition level
        if len(profiles) > 5:
            factors.append({
                "factor": "High Competition",
                "impact": "negative",
                "weight": 0.2,
                "mitigation": "Focus on strong discriminators and unique value",
            })

        return factors

    def _generate_positioning(
        self,
        gaps: List[Dict],
        eval_criteria: List[Dict]
    ) -> List[Dict]:
        """Generate recommended strategic positioning"""
        positioning = []

        for gap in gaps[:5]:
            positioning.append({
                "recommendation": gap.get("opportunity", ""),
                "priority": "high" if gap.get("competitor_count", 0) >= 2 else "medium",
                "integration_point": "All major sections",
            })

        return positioning

    def _ghosting_to_dict(self, gs: GhostingStrategy) -> Dict[str, Any]:
        """Convert GhostingStrategy to dictionary"""
        return {
            "competitor_weakness": gs.competitor_weakness,
            "our_strength": gs.our_strength,
            "language_template": gs.language_template,
            "eval_criteria_link": gs.eval_criteria_link,
            "subtlety_level": gs.subtlety_level,
        }


def create_strategy_agent(
    llm_client: Optional[Any] = None,
    past_performance_store: Optional[Any] = None,
    llm_provider: str = "gemini",
    use_llm: bool = True
) -> StrategyAgent:
    """
    Factory function to create a Strategy Agent.

    v4.0: Now supports LLM provider configuration.

    Args:
        llm_client: Legacy LLM client (optional)
        past_performance_store: Vector store for past proposals
        llm_provider: LLM provider ("gemini", "anthropic", "openai")
        use_llm: Enable LLM-based theme generation

    Returns:
        Configured StrategyAgent instance
    """
    return StrategyAgent(
        llm_client=llm_client,
        past_performance_store=past_performance_store,
        llm_provider=llm_provider,
        use_llm=use_llm,
    )
